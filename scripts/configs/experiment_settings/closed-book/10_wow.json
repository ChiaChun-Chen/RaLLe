{
    "chain_config": {
        "dataset": {
            "dataset_name": "WoW",
            "num_evaluate": -1,
            "batch_size": 1
        },
        "len_chain": 1,
        "chain": [
            {
                "prompt_template": "Output a short and informative reply to the conversation. This conversation ends on your turn.\n\n{question}\n\nInformative and short answer: ",
                "function": "LLM",
                "llm_name": "llama-2-13b-chat",
                "f-strings_or_eval": "f-strings"
            }
        ]
    }
}
